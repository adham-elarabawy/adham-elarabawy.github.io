/*! For license information please see component---src-templates-project-page-tsx-content-file-path-src-projects-direct-inversion-mdx-0da1bc130fbd052ac8fd.js.LICENSE.txt */
"use strict";(self.webpackChunkmy_gatsby_site=self.webpackChunkmy_gatsby_site||[]).push([[676],{3062:function(e,t,n){n.r(t),n.d(t,{default:function(){return f}});var r=n(8453),i=n(6540);function a(e){const t=Object.assign({h4:"h4",p:"p",strong:"strong",a:"a",em:"em"},(0,r.R)(),e.components);return i.createElement(i.Fragment,null,i.createElement(t.h4,null,"Paper Preview"),"\n",i.createElement("div",{style:{display:"flex",justifyContent:"center",alignItems:"center"}},i.createElement("img",{src:"/images/direct_inversion_thumbnail.png",alt:"Alt text",title:"Image Title",style:{width:"500px"}})),"\n",i.createElement("div",{style:{display:"flex",justifyContent:"center",alignItems:"center"}},i.createElement(t.p,null,i.createElement(t.strong,null,i.createElement(t.a,{href:"https://arxiv.org/abs/2211.07825"},"Arxiv Preprint")))),"\n",i.createElement(t.h4,null,"Abstract"),"\n",i.createElement(t.p,null,"With the rise of large, publicly-available text-to-image diffusion models, text-guided real image editing has garnered much research attention recently. Existing methods tend to either rely on some form of per-instance or per-task fine-tuning and optimization, require multiple novel views, or they inherently entangle preservation of real image identity, semantic coherence, and faithfulness to text guidance. In this paper, we propose an optimization-free and zero fine-tuning framework that applies complex and non-rigid edits to a single real image via a text prompt, avoiding all the pitfalls described above. Using widely-available generic pre-trained text-to-image diffusion models, we demonstrate the ability to modulate pose, scene, background, style, color, and even racial identity in an extremely flexible manner through a single target text detailing the desired edit. Furthermore, our method, which we name ",i.createElement(t.em,null,"Direct Inversion"),", proposes multiple intuitively configurable hyperparameters to allow for a wide range of types and extents of real image edits. We prove our method's efficacy in producing high-quality, diverse, semantically coherent, and faithful real image edits through applying it on a variety of inputs for a multitude of tasks. We also formalize our method in well-established theory, detail future experiments for further improvement, and compare against state-of-the-art attempts."))}var o=function(e){void 0===e&&(e={});const{wrapper:t}=Object.assign({},(0,r.R)(),e.components);return t?i.createElement(t,e,i.createElement(a,e)):a(e)},l=n(4794),s=n(1503),c=n(2659),m=n(5133),u=n(103);const d={Link:l.Link};function p(e){let{data:t,children:n}=e;return i.createElement(s.M,null,i.createElement(c.m,{pt:100},i.createElement(m.$,{leftSection:i.createElement(u.A,{size:14}),onClick:()=>{(0,l.navigate)("/")}},"Back to Projects"),i.createElement("h1",null,t.mdx.frontmatter.title),i.createElement("p",null,t.mdx.frontmatter.description),i.createElement(r.x,{components:d},n)))}function f(e){return i.createElement(p,e,i.createElement(o,e))}},8453:function(e,t,n){n.d(t,{R:function(){return o},x:function(){return l}});var r=n(6540);const i={},a=r.createContext(i);function o(e){const t=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),r.createElement(a.Provider,{value:t},e.children)}},103:function(e,t,n){n.d(t,{A:function(){return r}});var r=(0,n(8728).A)("outline","arrow-left","IconArrowLeft",[["path",{d:"M5 12l14 0",key:"svg-0"}],["path",{d:"M5 12l6 6",key:"svg-1"}],["path",{d:"M5 12l6 -6",key:"svg-2"}]])}}]);
//# sourceMappingURL=component---src-templates-project-page-tsx-content-file-path-src-projects-direct-inversion-mdx-0da1bc130fbd052ac8fd.js.map